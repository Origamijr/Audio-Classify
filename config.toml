[preprocessing]
# Input Settings
file_types = ["flac", "mp3"]
source = "../datasets/vctk/VCTK-Corpus-0.92/wav48_silence_trimmed"
category_level = 0 # distance from source to category folder level

# Output Settings
destination = "dataset/vctk/mel_22050_2048_512_80_72_36.h5"
hdf_label_key = 'keys'

# Preprocessing Parameters
sr = 22050
keep_wave = false

# Data Culling
min_sequence = 4
min_category_count = 20


[preprocessing.features]
# Types of features include the following:
# mel - mel spectrogram (n_bins, chunk_size)
# stft - short-time fourier transform (1 + n_fft/2, chunk_size)
# cqt - constant q transform (n_bins, chunk_size)
# none - none (set keep_wave to true for waveform data)
type = 'mel'

# number of fft bins
n_fft = 2048

# size of window (probably best be same as n_fft)
win_length = 2048

# Number of audio frames between windows
hop_size = 512

# number of bins (chroma bins in cqt, mel bins for mel)
n_bins = 80

# Number of time frames per datum (duration between frames = chunk_size * hop_size / sr)
chunk_size = 72

# Number of overlapping time frames between adjacent datum
overlap = 36

# Right pads last datum with zeros if true
padding = true


[training]
train_val_test_split = [0.7, 0.1, 0.2]
split_seed = 42
batch_size = 128
eval_batch_size = 128
shuffle = true
max_epochs = 20
enable_logging = false
log_dir = './logs/'
model_dir = './models/' # TODO not implemented yet

[training.optimizer]
type = 'adam' # hard coded, does nothing for now
lr = 1e-5
#momentum = 0.9
amsgrad = true


# Convolutional Encoder processes 2d spectrogram info as multichanneled 1D data
[model.1d_convolutional_encoder.initialization]
    type = 'kaiming_normal' # TODO hard coded rn, doesn't do anything
    nonlinearity = 'linear'
[[model.1d_convolutional_encoder.stack]]
    type = 'conv1d'
    in_channels = 80
    out_channels = 256
    kernel_size = 7
    padding = 3

    [[model.1d_convolutional_encoder.stack]]
    type = 'relu'

    [[model.1d_convolutional_encoder.stack]]
    type = 'layernorm'
    normalized_shape = [256, 72]

    [[model.1d_convolutional_encoder.stack]]
    type = 'conv1d'
    in_channels = 256
    out_channels = 256
    kernel_size = 7
    padding = 3

    [[model.1d_convolutional_encoder.stack]]
    type = 'relu'

    [[model.1d_convolutional_encoder.stack]]
    type = 'layernorm'
    normalized_shape = [256, 72]

    [[model.1d_convolutional_encoder.stack]]
    type = 'conv1d'
    in_channels = 256
    out_channels = 256
    kernel_size = 5
    stride = 2
    padding = 2

    [[model.1d_convolutional_encoder.stack]]
    type = 'relu'

    [[model.1d_convolutional_encoder.stack]]
    type = 'residual'
    rezero = true
    repeat = 30
    
        [[model.1d_convolutional_encoder.stack.cell]]
        type = 'sequential'
        repeat = 2

            [[model.1d_convolutional_encoder.stack.cell.cell]]
            type = 'relu'

            [[model.1d_convolutional_encoder.stack.cell.cell]]
            type = 'layernorm'
            normalized_shape = [256, 36]

            [[model.1d_convolutional_encoder.stack.cell.cell]]
            type = 'conv1d'
            in_channels = 256
            out_channels = 256
            kernel_size = 5
            padding = 2

    [[model.1d_convolutional_encoder.stack]]
    type = 'relu'

    [[model.1d_convolutional_encoder.stack]]
    type = 'layernorm'
    normalized_shape = [256, 36]

    [[model.1d_convolutional_encoder.stack]]
    type = 'conv1d'
    in_channels = 256
    out_channels = 128
    kernel_size = 1

    [[model.1d_convolutional_encoder.stack]]
    type = 'relu'

    [[model.1d_convolutional_encoder.stack]]
    type = 'layernorm'
    normalized_shape = [128, 36]

    [[model.1d_convolutional_encoder.embedding]]
    type = 'linear'
    in_features = 4608
    out_features = 128

    [[model.1d_convolutional_encoder.embedding]]
    type = 'relu'

    [[model.1d_convolutional_encoder.embedding]]
    type = 'layernorm'
    normalized_shape = 128



[model.crnn.rnn]
    type = 'gru'
    input_size = 128
    hidden_size = 256
    num_layers = 1
    batch_first = true


[[model.crnn.classifier]]
    type = 'linear'
    in_features = 256
    out_features = 64

    [[model.crnn.classifier]]
    type = 'dropout'
    p = 0.2

    [[model.crnn.classifier]]
    type = 'selu'

    [[model.crnn.classifier]]
    type = 'linear'
    in_features = 64
    out_features = 110 # number of labels in the dataset