[preprocessing]
# Input Settings
file_types = ["flac", "mp3"]
source = "../datasets/vctk/VCTK-Corpus-0.92/wav48_silence_trimmed"
category_level = 0 # distance from source to category folder level

# Output Settings
destination = "dataset/vctk/mel_22050_2048_512_80_72_36.h5"
hdf_label_key = 'keys'

# Preprocessing Parameters
sr = 22050
keep_wave = false

# Data Culling
min_sequence = 4
min_category_count = 20


[preprocessing.features]
# Types of features include the following:
# mel - mel spectrogram (n_bins, chunk_size)
# stft - short-time fourier transform (1 + n_fft/2, chunk_size)
# cqt - constant q transform (n_bins, chunk_size)
# none - none (set keep_wave to true for waveform data)
type = 'mel'

# number of fft bins
n_fft = 2048

# size of window (probably best be same as n_fft)
win_length = 2048

# Number of audio frames between windows
hop_size = 512

# number of bins (chroma bins in cqt, mel bins for mel)
n_bins = 80

# Number of time frames per datum (duration between frames = chunk_size * hop_size / sr)
chunk_size = 72

# Number of overlapping time frames between adjacent datum
overlap = 36

# Right pads last datum with zeros if true
padding = true


[training]
batch_size = 4
shuffle = true
max_epochs = 100
log_dir = './logs/'


# Convolutional Encoder processes 2d spectrogram into
[[model.convolutional_encoder]]
    type = 'conv2d'
    in_channels = 1
    out_channels = 100
    kernel_size = [5, 5]
    padding = [2, 2]

    [[model.convolutional_encoder]]
    type = 'relu'

    [[model.convolutional_encoder]]
    type = 'conv2d'
    in_channels = 100
    out_channels = 100
    kernel_size = [5, 5]
    stride = [1, 1]
    padding = [2, 2]

    [[model.convolutional_encoder]]
    type = 'relu'

    [[model.convolutional_encoder]]
    type = 'conv2d'
    in_channels = 100
    out_channels = 100
    kernel_size = [3, 3]
    stride = [2, 2]
    padding = [1, 1]

    [[model.convolutional_encoder]]
    type = 'relu'

    [[model.convolutional_encoder]]
    type = 'residual'
    repeat = 5

        [[model.convolutional_encoder.cell]]
        type = 'relu'

        [[model.convolutional_encoder.cell]]
        type = 'conv2d'
        in_channels = 100
        out_channels = 100
        kernel_size = [3, 3]
        padding = [1, 1]

        [[model.convolutional_encoder.cell]]
        type = 'relu'

        [[model.convolutional_encoder.cell]]
        type = 'conv2d'
        in_channels = 100
        out_channels = 100
        kernel_size = [3, 3]
        padding = [1, 1]

    [[model.convolutional_encoder]]
    type = 'conv2d'
    in_channels = 100
    out_channels = 1
    kernel_size = [1, 1]

    [[model.convolutional_encoder]]
    type = 'flatten'
    start_dim = 1

    [[model.convolutional_encoder]]
    type = 'linear'
    in_features = 1440
    out_features = 100

    # maybe there should be normalization or activation here?


[model.crnn.rnn]
    type = 'gru'
    input_size = 100
    hidden_size = 100
    num_layers = 2
    batch_first = true


[[model.crnn.classifier]]
    type = 'linear'
    in_features = 100
    out_features = 64

    [[model.crnn.classifier]]
    type = 'tanh'

    [[model.crnn.classifier]]
    type = 'linear'
    in_features = 64
    out_features = 110 # number of labels in the dataset